{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[핸즈온]_Chapter1_한눈에 보는 머신러닝.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbQbvyHjjQu7DAyFR8OfqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sejin-sim/Hands_On_ML/blob/master/%5B%ED%95%B8%EC%A6%88%EC%98%A8%5D_Chapter1_%ED%95%9C%EB%88%88%EC%97%90_%EB%B3%B4%EB%8A%94_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mKP78TeZ0nd"
      },
      "source": [
        "### 1. 머신러닝이란?\r\n",
        "1. 정의 : 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구\r\n",
        "2. 공학적인 정의 : 어떤 작업 T에 대한 컴퓨터 프로그램 성능을 P로 측정했을 때 경험E로 인해 성능이 향상됐다면, 이 컴퓨터 프로그램은 **작업 T**와 **성능 측정 P**에 대해 **경험 E**로 학습한 것이다.   \r\n",
        " ex) 스팸 메일 분류 : mail 구분이 T, 분류된 파일 비율 P, 훈련 데이터 E\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 2. 왜 머신러닝을 사용하는가?\r\n",
        "- 데이터 마이닝 : 머신러닝 기술을 적용해서 대용량의 데이터를 분석하면 겉으로 보이지 않는 패턴을 발견할 수 있다.\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 3. 머신러닝 시스템의 종류\r\n",
        "1. 지도 학습 : 알고리즈멩 주입하는 훈련데이터 레이블이라는 원하는 답이 포함   \r\n",
        " 1) 분류(classification) : 전형적인 지도 학습 ex) 스팸 필터   \r\n",
        " 2) 회귀(regression) : 예측 변수(predictor variable)라 부르는 특성(feature)을 사용해 타겟(target) 수치를 예측하는 것. ex) 중고차 가격 예측   \r\n",
        " 3) 알고리즘\r\n",
        "  - k-최근접 이웃 (k-nearest neightbors)\r\n",
        "  - 선형 회귀 (linear regression)\r\n",
        "  - 로지스틱 회귀 (logistic regression)\r\n",
        "  - 서포트 백터 머신 (support vector machine SVM)\r\n",
        "  - 결정트리와 랜덤포레스트 (desicion tree and random forest)\r\n",
        "  - 신경망 (neural networks)\r\n",
        "<br/>\r\n",
        "2. 비지도 학습 : 훈련 데이터에 레이블이 없다.\r\n",
        " 1) 알고리즘\r\n",
        "  - 군집(clustering) : 계층 군집(hierachical clustering)\r\n",
        "  - 시각화와 차원 축소(visusalization and dimensionality reduction) : 특성 추출(feature extraction)\r\n",
        "  - 이상치 탐지(outlier detection) & 특이치 탐지(novelty detection) : 특이치 탐지는 모든 샘플과 달라 보이는 새로운 샘플을 탐지. 깨끗한 데이터가 필요\r\n",
        "  - 연관 규칙 학습(association rule learning) : 대량의 데이터에서 특성 간의 흥미로운 관계를 찾는다.\r\n",
        "<br/>\r\n",
        "3. 준지도 학습 : 일부만 레이블이 있는 데이터 지도 + 비지도\r\n",
        " - ex) 심층 신뢰 신경망(DBN), 제한된 볼츠만 머신(RBM)\r\n",
        " <br/>\r\n",
        "4. 강화 학습\r\n",
        " - 학습하는 시스템을 에이전트라고 부르며, 환경을 관찰해서 행동을 실행하고 결과로 보상 또는 벌점을 받는다. 큰 보상을 얻기 위해 정책이라고 부르는 최상의 전략을 스스로 학습한다.\r\n",
        " - ex) 딥마인드의 알파고(Alphago)\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 4. 머신러닝 시스템 분류의 다른 기준\r\n",
        "- 입력 데이터의 스트림부터 점진적으로 학습할 수 있는지 여부\r\n",
        "1. 배치 학습(batch learning) = 오프라인 학습\r\n",
        " - 시스템이 점진적으로 학습할 수 없고, 가용한 데이터를 모두 사용해 훈련\r\n",
        " - 새로운 데이터 학습하려면 전체 데이터를 사용하여 시스템의 새로운 버전을 처음부터 다시 훈련\r\n",
        " - 보통 24시간 or 매주 시스템을 훈련 시킨다.\r\n",
        " - 많은 컴퓨터 자원이 필요하다.\r\n",
        "</br>\r\n",
        "2. 점진적 학습(incremental learning) = 온라인 학습   \r\n",
        " 1) 정의\r\n",
        "  - 데이터를 순차적 또는 한개씩 또는 미니배치라 부르는 작은 묶은 단위로 주입하여 시스템을 훈련\r\n",
        "  - 매 학습 단계가 빠르고 비용이 적게 들어서 데이터 도착 즉시 학습가능\r\n",
        "  - 연속적으로 데이터를 받고 빠른 변화에 스스로 적응해야 하는 시스템에 적합하다.\r\n",
        " - 메인 메모리에 들어갈 수 없는 큰 데이터셋을 학습하는 시스템에도 온라인 학습 알고리즘 사용 가능 ( = out of core, 외부 메모리 학습)   \r\n",
        "\r\n",
        " 2) 주요 파라미터\r\n",
        " - 학습률(learning rate) : 변화하는 데이터에 얼마나 빠르게 적응할 것인지\r\n",
        " - 학습률 ↑ : 시스템이 데이터에 빠르게 적용하지만, 이전 데이터를 금방 잊음.\r\n",
        " - 학습률 ↓ :시스템의 관성이 커져 더 느리게 학습. 하지만 잡음이나 대표성 없는 데이터 포인트에 덜 민감.\r\n",
        "\r\n",
        " 3) 문제점\r\n",
        "  - 나쁜 데이터가 주입되었을 떄 시스템 성능이 점진적으로 감소.   \r\n",
        "  ㄴ 성능 감지 감지시 즉각 학습 중지 필요. (ex. 이상치 탐지 알고리즘)\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 5. 사례 기반 학습과 모델 기반 학습\r\n",
        "- 일반화를 위한 두가지 접근법   \r\n",
        "1. 사례 기반 학습(instance-based learning) : 시스템이 훈련 샘플을 기억함으로써 학습을 하고, 유사도(similarity) 측정을 통해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화   \r\n",
        "2. 모델 기반 학습(mode-based learning) : 샘플들의 모델을 만들어 예측(prediction)에 사용하는 것\r\n",
        " - 효용 함수(utility function) : 모델이 얼마나 좋은지 측정\r\n",
        " - 비용 함수(cost function) : 모델이 얼마나 나쁜지 측정. 선형 회귀에서는 거리를 재는 비용함수를 보통 사용하고, 이를 최소화 하는 것이 목표이다.\r\n",
        " - 모델을 훈련 : 선형 회귀 알고리즘에 훈련데이터를 공급하여 데이터에 가장 잘 맞는 선형 모델의 파라미터를 찾는 것.\r\n",
        " - 작업 요약 : 데이터 분석 - 모델 선택 - 훈련 데이터로 모델을 훈련 - 새로운 데이터에 모델을 적용해 예측(= 추론 infrerence)하고 일반화 되길 기대\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 6. 머신러닝의 주요 도전 과자\r\n",
        "1. 충분하지 않은 양의 훈련 데이터\r\n",
        "2. 대표성 없는 훈련 데이터 \r\n",
        " - 샘플링 잡음(sampling noise) : 샘플이 작음. 우연에 의한 대표성 x.\r\n",
        " - 샘플링 편향(sampling bias) : 샘플이 크지만 추출 방법이 잘못됨. \r\n",
        "3. 낮은 품질의 데이터\r\n",
        " - 에러, 이상치, 잡음 : 성능이 낮은 측정 장치 때문에\r\n",
        "4. 관련 없는 특성 \r\n",
        " - 성공적인 머신러닝 프로젝트의 핵심 요소 = 특성 공학(feature enginerring) : 훈련에 사용할 좋은 특성을 찾는 것\r\n",
        " >- 특성 선택(feature selection) : 가지고 있는 특성 중 훈련에 가장 유용한 특성을 선택\r\n",
        " >- 특성 추출(feature extraction) : 특성을 결합하여 더 유용한 특성을 만든다.\r\n",
        " >- 새로운 데이터를 수집해 새 특성을 만든다.\r\n",
        "\r\n",
        "### 7. 훈련 데이터 과대 적합\r\n",
        " - 과대 적합(overfitting) : 모델이 훈련 데이터에 너무 잘 맞지만 일반성이 떨어짐.\r\n",
        "\r\n",
        "1. 발생 원인 : 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생.\r\n",
        "2. 해결 방안\r\n",
        " - 파라미터 수가 적은 모델을 선택(고차원 다항 모델보다 선형 모델), 데이터 특성 수를 줄이거나, 모델에 제약(=규제 regulation)을 가하여 단순화 시킨다.\r\n",
        " - 훈련 데이터를 더 많이 모은다.\r\n",
        " - 훈련데이터의 잡음을 줄인다. ex) 오류 데이터 수정과 이상치 제거\r\n",
        "3. 규제(regulation) : 모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것.   \r\n",
        "ㄴ 자유도(degree of freedom)을 줄인다.\r\n",
        "\r\n",
        "<br/>\r\n",
        "\r\n",
        "### 8. 훈련 데이터 과소 적합\r\n",
        "- 과소 적합(underfitting) : 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못함\r\n",
        "- 해결 방안 \r\n",
        " - 모델 파라미터가 더 많은 강력한 모델을 선택\r\n",
        " - 학습 알고리즘에 더 좋은 특성을 제공(특성 공학)\r\n",
        " - 모델의 제약을 줄인다.(ex. 규제 하이퍼파라미터를 ↓)\r\n",
        "\r\n",
        "</br>\r\n",
        "\r\n",
        "### 9. 테스트와 검증\r\n",
        "- 훈련데이터를 훈련세트와 테스트세트(validation set)로 나눠서 사용\r\n",
        "- 일반화 오차(generalization error) : 새로운 샘플에 대한 오류 비율.\r\n",
        "- 일반화 오차에 대해 테스트 세트에서 모델을 평가해서 추정값(estimation)을 얻는다.\r\n",
        "- 훈련 오차 ↓ & 일반화 오차 ↑ = 과대 적합(overfitiing)\r\n",
        "1. 홀드아웃 검증(holdout validation) : 훈련세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택.\r\n",
        "2. 교차 검증(cross-validation) : 작은 검증 세트를 여러 개 사용해 반복적인 교차 검증을 수행. 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가\r\n",
        "![](https://s3.amazonaws.com/higherlogicdownload/H2OAI/UploadedImages/DD2AamkLQCiML6GZINon_15.jpg)\r\n",
        "\r\n"
      ]
    }
  ]
}